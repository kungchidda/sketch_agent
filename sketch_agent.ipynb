{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67281ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8987b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!/usr/bin/env -S uv run --script\n",
    "# /// script\n",
    "# dependencies = [\n",
    "#   \"anthropic>=0.45.0\",\n",
    "#   \"openai>=1.24.0\",\n",
    "# ]\n",
    "# ///\n",
    "import os\n",
    "import subprocess\n",
    "from typing import Dict, List, Any, Optional, Tuple, Union\n",
    "\n",
    "import anthropic\n",
    "import openai\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58eb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"\\n=== LLM Agent Loop with Claude and Bash Tool ===\\n\")\n",
    "        print(\"Type 'exit' to end the conversation.\\n\")\n",
    "        provider = os.getenv(\"MODEL_PROVIDER\", \"anthropic\").lower()\n",
    "        if provider == \"openai\":\n",
    "            model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "            loop(LLMOpenAI(model_name))\n",
    "        else:\n",
    "            loop(LLM(\"claude-3-7-sonnet-latest\"))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nExiting. Goodbye!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nAn error occurred: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0572fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loop(llm):\n",
    "    provider = getattr(llm, \"provider\", \"anthropic\")\n",
    "    msg = user_input()            # first user msg\n",
    "    while True:\n",
    "        # ① assistant responds\n",
    "        output, tool_calls = llm(msg)\n",
    "        if output:\n",
    "            print(\"Agent: \", output)\n",
    "\n",
    "        # ② if assistant called tools → run them & feed results back\n",
    "        if tool_calls:\n",
    "            tool_results = [handle_tool_call(tc, provider) for tc in tool_calls]\n",
    "            # Immediately send tool results back to the LLM\n",
    "            msg = tool_results\n",
    "            continue              # repeat loop without new user input\n",
    "        # ③ no tool calls → ask user again\n",
    "        msg = user_input()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bash_tool = {\n",
    "    \"name\": \"bash\",\n",
    "    \"description\": \"Execute bash commands and return the output\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"command\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The bash command to execute\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"command\"]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to execute bash commands\n",
    "def execute_bash(command):\n",
    "    \"\"\"Execute a bash command and return a formatted string with the results.\"\"\"\n",
    "    # If we have a timeout exception, we'll return an error message instead\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"bash\", \"-c\", command],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        return f\"STDOUT:\\n{result.stdout}\\nSTDERR:\\n{result.stderr}\\nEXIT CODE: {result.returncode}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error executing command: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a3a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def user_input():\n",
    "    x = input(\"You: \")\n",
    "    if x.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"\\nExiting agent loop. Goodbye!\")\n",
    "        raise SystemExit(0)\n",
    "    return [{\"type\": \"text\", \"text\": x}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, model):\n",
    "        if \"ANTHROPIC_API_KEY\" not in os.environ:\n",
    "            raise ValueError(\"ANTHROPIC_API_KEY environment variable not found.\")\n",
    "        self.client = anthropic.Anthropic()\n",
    "        self.model = model\n",
    "        self.provider = \"anthropic\"\n",
    "        self.messages = []\n",
    "        self.system_prompt = \"\"\"You are a helpful AI assistant with access to bash commands.\n",
    "        You can help the user by executing commands and interpreting the results.\n",
    "        Be careful with destructive commands and always explain what you're doing.\n",
    "        You have access to the bash tool which allows you to run shell commands.\"\"\"\n",
    "        self.tools = [bash_tool]\n",
    "\n",
    "    def __call__(self, content):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "        self.messages[-1][\"content\"][-1][\"cache_control\"] = {\"type\": \"ephemeral\"}\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=20_000,\n",
    "            system=self.system_prompt,\n",
    "            messages=self.messages,\n",
    "            tools=self.tools\n",
    "        )\n",
    "        del self.messages[-1][\"content\"][-1][\"cache_control\"]\n",
    "        assistant_response = {\"role\": \"assistant\", \"content\": []}\n",
    "        tool_calls = []\n",
    "        output_text = \"\"\n",
    "\n",
    "        for content in response.content:\n",
    "            if content.type == \"text\":\n",
    "                text_content = content.text\n",
    "                output_text += text_content\n",
    "                assistant_response[\"content\"].append({\"type\": \"text\", \"text\": text_content})\n",
    "            elif content.type == \"tool_use\":\n",
    "                assistant_response[\"content\"].append(content)\n",
    "                tool_calls.append({\n",
    "                    \"id\": content.id,\n",
    "                    \"name\": content.name,\n",
    "                    \"input\": content.input\n",
    "                })\n",
    "\n",
    "        self.messages.append(assistant_response)\n",
    "        return output_text, tool_calls\n",
    "\n",
    "\n",
    "class LLMOpenAI:\n",
    "    \"\"\"\n",
    "    OpenAI‑based drop‑in replacement for the Anthropic‑backed LLM.\n",
    "    It expects an environment variable OPENAI_API_KEY and supports the same\n",
    "    bash tool interface.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: str):\n",
    "        if \"OPENAI_API_KEY\" not in os.environ:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable not found.\")\n",
    "        openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        self.model = model\n",
    "        self.provider = \"openai\"\n",
    "        self.messages = []\n",
    "        self.system_prompt = \"\"\"You are a helpful AI assistant with access to bash commands.\n",
    "You can help the user by executing commands and interpreting the results.\n",
    "Be careful with destructive commands and always explain what you're doing.\n",
    "You have access to the bash tool which allows you to run shell commands.\"\"\"\n",
    "        # OpenAI requires each tool to be wrapped with {\"type\": \"function\", \"function\": ...}\n",
    "        self.tools = [{ \"type\": \"function\", \"function\": bash_tool }]\n",
    "\n",
    "    def __call__(self, content):\n",
    "        # Detect whether `content` is (a) list of {type:'text'} parts\n",
    "        #      → user input, or (b) list of {role:'tool', ...} messages.\n",
    "        if content and isinstance(content, list) and \"role\" in content[0]:\n",
    "            # tool result messages; just extend history\n",
    "            self.messages.extend(content)\n",
    "        else:\n",
    "            user_text = \" \".join(\n",
    "                part[\"text\"] for part in content\n",
    "                if isinstance(part, dict) and part.get(\"type\") == \"text\"\n",
    "            )\n",
    "            self.messages.append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "        # Call OpenAI Chat Completions with tool support\n",
    "        response = openai.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"system\", \"content\": self.system_prompt}] + self.messages,\n",
    "            tools=self.tools,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        assistant_msg = response.choices[0].message\n",
    "        output_text = assistant_msg.content or \"\"\n",
    "        tool_calls = []\n",
    "\n",
    "        # Parse tool calls (if any)\n",
    "        if getattr(assistant_msg, \"tool_calls\", None):\n",
    "            for tc in assistant_msg.tool_calls:\n",
    "                tool_calls.append(\n",
    "                    {\n",
    "                        \"id\": tc.id,\n",
    "                        \"name\": tc.function.name,\n",
    "                        \"input\": json.loads(tc.function.arguments or \"{}\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Keep full assistant message history for context\n",
    "        self.messages.append(assistant_msg.to_dict())\n",
    "        return output_text, tool_calls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def handle_tool_call(tool_call, provider=\"anthropic\"):\n",
    "    if tool_call[\"name\"] != \"bash\":\n",
    "        raise Exception(f\"Unsupported tool: {tool_call['name']}\")\n",
    "\n",
    "    command = tool_call[\"input\"][\"command\"]\n",
    "    print(f\"Executing bash command: {command}\")\n",
    "    output_text = execute_bash(command)\n",
    "    print(f\"Bash output:\\n{output_text}\")\n",
    "\n",
    "    if provider == \"openai\":\n",
    "        # OpenAI expects a role='tool' message referencing the call id\n",
    "        return {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "            \"content\": output_text\n",
    "        }\n",
    "    else:  # Anthropic\n",
    "        return {\n",
    "            \"type\": \"tool_result\",\n",
    "            \"tool_use_id\": tool_call[\"id\"],\n",
    "            \"content\": [ { \"type\": \"text\", \"text\": output_text } ]\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
