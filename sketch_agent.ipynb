{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f04444f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341eb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!/usr/bin/env -S uv run --script\n",
    "# /// script\n",
    "# dependencies = [\n",
    "#   \"anthropic>=0.45.0\",\n",
    "#   \"openai>=1.24.0\",\n",
    "# ]\n",
    "# ///\n",
    "import os\n",
    "import subprocess\n",
    "from typing import Dict, List, Any, Optional, Tuple, Union\n",
    "\n",
    "import anthropic\n",
    "import openai\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"\\n=== LLM Agent Loop with Claude and Bash Tool ===\\n\")\n",
    "        print(\"Type 'exit' to end the conversation.\\n\")\n",
    "        provider = os.getenv(\"MODEL_PROVIDER\", \"anthropic\").lower()\n",
    "        if provider == \"openai\":\n",
    "            model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "            loop(LLMOpenAI(model_name))\n",
    "        else:\n",
    "            loop(LLM(\"claude-3-7-sonnet-latest\"))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nExiting. Goodbye!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nAn error occurred: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loop(llm):\n",
    "    msg = user_input()\n",
    "    while True:\n",
    "        output, tool_calls = llm(msg)\n",
    "        print(\"Agent: \", output)\n",
    "        if tool_calls:\n",
    "            msg = [ handle_tool_call(tc) for tc in tool_calls ]\n",
    "        else:\n",
    "            msg = user_input()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84062b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bash_tool = {\n",
    "    \"name\": \"bash\",\n",
    "    \"description\": \"Execute bash commands and return the output\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"command\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The bash command to execute\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"command\"]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ea89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to execute bash commands\n",
    "def execute_bash(command):\n",
    "    \"\"\"Execute a bash command and return a formatted string with the results.\"\"\"\n",
    "    # If we have a timeout exception, we'll return an error message instead\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"bash\", \"-c\", command],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        return f\"STDOUT:\\n{result.stdout}\\nSTDERR:\\n{result.stderr}\\nEXIT CODE: {result.returncode}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error executing command: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def user_input():\n",
    "    x = input(\"You: \")\n",
    "    if x.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"\\nExiting agent loop. Goodbye!\")\n",
    "        raise SystemExit(0)\n",
    "    return [{\"type\": \"text\", \"text\": x}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, model):\n",
    "        if \"ANTHROPIC_API_KEY\" not in os.environ:\n",
    "            raise ValueError(\"ANTHROPIC_API_KEY environment variable not found.\")\n",
    "        self.client = anthropic.Anthropic()\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "        self.system_prompt = \"\"\"You are a helpful AI assistant with access to bash commands.\n",
    "        You can help the user by executing commands and interpreting the results.\n",
    "        Be careful with destructive commands and always explain what you're doing.\n",
    "        You have access to the bash tool which allows you to run shell commands.\"\"\"\n",
    "        self.tools = [bash_tool]\n",
    "\n",
    "    def __call__(self, content):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "        self.messages[-1][\"content\"][-1][\"cache_control\"] = {\"type\": \"ephemeral\"}\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=20_000,\n",
    "            system=self.system_prompt,\n",
    "            messages=self.messages,\n",
    "            tools=self.tools\n",
    "        )\n",
    "        del self.messages[-1][\"content\"][-1][\"cache_control\"]\n",
    "        assistant_response = {\"role\": \"assistant\", \"content\": []}\n",
    "        tool_calls = []\n",
    "        output_text = \"\"\n",
    "\n",
    "        for content in response.content:\n",
    "            if content.type == \"text\":\n",
    "                text_content = content.text\n",
    "                output_text += text_content\n",
    "                assistant_response[\"content\"].append({\"type\": \"text\", \"text\": text_content})\n",
    "            elif content.type == \"tool_use\":\n",
    "                assistant_response[\"content\"].append(content)\n",
    "                tool_calls.append({\n",
    "                    \"id\": content.id,\n",
    "                    \"name\": content.name,\n",
    "                    \"input\": content.input\n",
    "                })\n",
    "\n",
    "        self.messages.append(assistant_response)\n",
    "        return output_text, tool_calls\n",
    "\n",
    "\n",
    "class LLMOpenAI:\n",
    "    \"\"\"\n",
    "    OpenAI‑based drop‑in replacement for the Anthropic‑backed LLM.\n",
    "    It expects an environment variable OPENAI_API_KEY and supports the same\n",
    "    bash tool interface.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: str):\n",
    "        if \"OPENAI_API_KEY\" not in os.environ:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable not found.\")\n",
    "        openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "        self.system_prompt = \"\"\"You are a helpful AI assistant with access to bash commands.\n",
    "You can help the user by executing commands and interpreting the results.\n",
    "Be careful with destructive commands and always explain what you're doing.\n",
    "You have access to the bash tool which allows you to run shell commands.\"\"\"\n",
    "        # OpenAI requires each tool to be wrapped with {\"type\": \"function\", \"function\": ...}\n",
    "        self.tools = [{ \"type\": \"function\", \"function\": bash_tool }]\n",
    "\n",
    "    def __call__(self, content):\n",
    "        # Convert Anthropics rich content list → plain user text\n",
    "        user_text = \" \".join(\n",
    "            part[\"text\"] for part in content if isinstance(part, dict) and part.get(\"type\") == \"text\"\n",
    "        )\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "        # Call OpenAI Chat Completions with tool support\n",
    "        response = openai.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"system\", \"content\": self.system_prompt}] + self.messages,\n",
    "            tools=self.tools,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        assistant_msg = response.choices[0].message\n",
    "        output_text = assistant_msg.content or \"\"\n",
    "        tool_calls = []\n",
    "\n",
    "        # Parse tool calls (if any)\n",
    "        if getattr(assistant_msg, \"tool_calls\", None):\n",
    "            for tc in assistant_msg.tool_calls:\n",
    "                tool_calls.append(\n",
    "                    {\n",
    "                        \"id\": tc.id,\n",
    "                        \"name\": tc.function.name,\n",
    "                        \"input\": json.loads(tc.function.arguments or \"{}\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Keep full assistant message history for context\n",
    "        self.messages.append(assistant_msg.to_dict())\n",
    "        return output_text, tool_calls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def handle_tool_call(tool_call):\n",
    "    if tool_call[\"name\"] != \"bash\":\n",
    "        raise Exception(f\"Unsupported tool: {tool_call['name']}\")\n",
    "\n",
    "    command = tool_call[\"input\"][\"command\"]\n",
    "    print(f\"Executing bash command: {command}\")\n",
    "    output_text = execute_bash(command)\n",
    "    print(f\"Bash output:\\n{output_text}\")\n",
    "    return dict(\n",
    "        type=\"tool_result\",\n",
    "        tool_use_id=tool_call[\"id\"],\n",
    "        content=[dict(\n",
    "            type=\"text\",\n",
    "            text=output_text\n",
    "        )]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641dec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
